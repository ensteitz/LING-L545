# Tokenization Practical:

## Instructions: need to be updated

   The results from this practical are seen in the test and train files.

   To see the result of the ... do the following line in terminal:

    `cat encoded_wiki.txt | python3 segmenter.py`


   In my language, Sardinian, there were several unique challenges for segmentation --particularly in response to sentence ambiguities. Most of these were resolved. To see more, look at the note at the beginning of the segmenter.py file.


## Results: need to be updated

   I stored the results of this command in the file `segmented_wiki.txt`.

   If you wanted to store it in a file for yourself using the command line, please run this line through terminal:

    `cat encoded\_wiki.txt | python3 segmenter.py > segmented\_wiki.txt`


## References:

1. Straka, M., & Strakov√°, J. (2017, August). Tokenizing, pos tagging, lemmatizing and parsing ud 2.0 with udpipe. In Proceedings of the CoNLL 2017 shared task: Multilingual parsing from raw text to universal dependencies (pp. 88-99).
2. 
